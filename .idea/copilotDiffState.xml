<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/TEST_SUITE_README.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/TEST_SUITE_README.md" />
              <option name="updatedContent" value="# Test Suite Documentation&#10;&#10;## Overview&#10;This project includes comprehensive tests to replicate and debug the `'NoneType' object has no attribute 'shape'` error encountered during LoRA training.&#10;&#10;## Test Files&#10;&#10;### 1. `test_training.py` - Unit Tests&#10;Comprehensive unit tests for individual components of the training pipeline.&#10;&#10;**Tests Included:**&#10;&#10;#### `TestCharacterDataset.test_dataset_loading()`&#10;- Tests image loading from disk&#10;- Validates dataset returns proper tensors without None values&#10;- Checks prompt/caption loading&#10;&#10;**Run:**&#10;```bash&#10;python test_training.py&#10;```&#10;&#10;**What it tests:**&#10;- ✓ Images load correctly&#10;- ✓ Images resize to proper dimensions&#10;- ✓ Tensor conversion works&#10;- ✓ Prompts load from .txt files&#10;- ✗ Identifies if dataset returns None values&#10;&#10;#### `TestPromptEncoding.test_encode_prompt_mock()`&#10;- Simulates `encode_prompt()` with mock pipeline&#10;- Tests normal case vs. broken cases&#10;- Shows what happens when encoder returns None&#10;&#10;**Scenario 1 - Normal:** `encode_prompt()` returns tuple of tensors&#10;```&#10;✓ encode_prompt returned tuple with shapes: torch.Size([1, 77, 768]), torch.Size([1, 1280])&#10;```&#10;&#10;**Scenario 2 - Broken:** `encode_prompt()` returns None&#10;```&#10;✗ encode_prompt returned None - THIS WOULD CAUSE THE ERROR!&#10;  Error would occur when trying: encoder_hidden_states = result[0]&#10;```&#10;&#10;#### `TestVAEEncoding.test_vae_encode_mock()`&#10;- Tests VAE latent encoding&#10;- Simulates VAE failure scenarios&#10;- Shows how None VAE output causes AttributeError&#10;&#10;**Scenario 1 - Normal:** VAE returns latent distribution&#10;```&#10;✓ VAE encoding returned tensor with shape: torch.Size([1, 4, 128, 128])&#10;```&#10;&#10;**Scenario 2 - Broken:** VAE returns None&#10;```&#10;✗ AttributeError caught: 'NoneType' object has no attribute 'latent_dist'&#10;```&#10;&#10;#### `TestUNetForward.test_unet_forward_mock()`&#10;- Tests UNet forward pass&#10;- Simulates prediction generation&#10;- Shows impact of None UNet output&#10;&#10;**Scenario 1 - Normal:** UNet returns prediction&#10;```&#10;✓ UNet forward returned tensor with shape: torch.Size([1, 4, 128, 128])&#10;```&#10;&#10;**Scenario 2 - Broken:** UNet returns None&#10;```&#10;✗ AttributeError caught: 'NoneType' object has no attribute 'sample'&#10;```&#10;&#10;#### `TestBatchProcessing.test_batch_with_none_prompts()`&#10;- Tests batch data integrity&#10;- Checks for None prompts&#10;- Validates empty string handling&#10;&#10;**Scenario 1 - Valid:** Normal batch with proper prompts&#10;```&#10;✓ Batch prompts valid: ['prompt 1', 'prompt 2']&#10;```&#10;&#10;**Scenario 2 - Broken:** None prompts in batch&#10;```&#10;✗ Batch prompt is None - THIS WOULD CAUSE ENCODE_PROMPT TO FAIL!&#10;```&#10;&#10;**Scenario 3 - Warning:** Empty string prompts&#10;```&#10;✗ Batch prompts are empty - encode_prompt may return unexpected results!&#10;```&#10;&#10;#### `TestDebugTrainingLoop.test_training_loop_debug()`&#10;- Full training loop simulation&#10;- Creates test dataset on disk&#10;- Processes batches with detailed output&#10;- Validates each step&#10;&#10;**Output:**&#10;```&#10;--- Batch 1 ---&#10;Batch keys: dict_keys(['pixel_values', 'prompt'])&#10;pixel_values type: &lt;class 'torch.Tensor'&gt;, shape: torch.Size([1, 3, 256, 256])&#10;prompt type: &lt;class 'list'&gt;, value: ['A test character number 1']&#10;✓ Prompts converted to list: ['A test character number 1']&#10;✓ Batch processing successful&#10;```&#10;&#10;---&#10;&#10;### 2. `test_integration.py` - Integration Tests&#10;Shows the broken training loop vs. the fixed version side-by-side.&#10;&#10;**Tests Included:**&#10;&#10;#### `FixedLoRATrainerTest.simulate_broken_training_loop()`&#10;Demonstrates **3 ways** the error occurs:&#10;&#10;**Broken Case 1: encode_prompt returns None**&#10;```&#10;[2] Encoding prompts (BROKEN: returns None)...&#10;prompt_embeds = None&#10;✗ ERROR (TypeError): 'NoneType' object is not subscriptable&#10;  This happens because prompt_embeds is None, and None[0] throws TypeError&#10;```&#10;&#10;**Broken Case 2: VAE encode returns None**&#10;```&#10;[3] VAE Encoding (BROKEN: returns None)...&#10;✗ ERROR (AttributeError): 'NoneType' object has no attribute 'latent_dist'&#10;  This happens because VAE.encode() returned None&#10;```&#10;&#10;**Broken Case 3: UNet returns None**&#10;```&#10;[4] UNet Forward (BROKEN: returns None)...&#10;✗ ERROR (AttributeError): 'NoneType' object has no attribute 'sample'&#10;  This happens because UNet forward returned None&#10;```&#10;&#10;#### `FixedLoRATrainerTest.simulate_fixed_training_loop()`&#10;Shows the **fixed version** with all validation checks:&#10;&#10;```&#10;[1] Processing batch with validation...&#10;✓ Batch validated: size=1, prompts=valid&#10;&#10;[2] Encoding prompts with validation...&#10;✓ Prompt embeddings valid: encoder_hidden_states shape=torch.Size([1, 77, 768])&#10;&#10;[3] VAE Encoding with validation...&#10;✓ Latents valid: shape=torch.Size([1, 4, 128, 128])&#10;&#10;[4] UNet Forward with validation...&#10;✓ UNet output valid: noise_pred shape=torch.Size([1, 4, 128, 128])&#10;&#10;[5] Loss computation...&#10;✓ Loss valid: 0.0019&#10;&#10;✓ FIXED TRAINING LOOP COMPLETED SUCCESSFULLY&#10;```&#10;&#10;#### `ProposedFix.print_fix()`&#10;Prints the complete proposed fix code showing all 5 fixes needed in `LoRATrainer.py`:&#10;&#10;- **FIX 1:** Validate batch contents&#10;- **FIX 2:** Validate prompts&#10;- **FIX 3:** Validate prompt embeddings&#10;- **FIX 4:** Validate VAE output&#10;- **FIX 5:** Validate UNet output&#10;&#10;**Run:**&#10;```bash&#10;python test_integration.py&#10;```&#10;&#10;---&#10;&#10;## Running the Tests&#10;&#10;### Run all unit tests:&#10;```bash&#10;python test_training.py&#10;```&#10;&#10;### Run integration tests:&#10;```bash&#10;python test_integration.py&#10;```&#10;&#10;### View test logs:&#10;```bash&#10;cat logs/test.log&#10;cat logs/integration_test.log&#10;```&#10;&#10;---&#10;&#10;## Expected Output&#10;&#10;### From `test_training.py`:&#10;```&#10;======================================================================&#10;SDXL LoRA Training - Debug Test Suite&#10;======================================================================&#10;&#10;=== Testing CharacterDataset ===&#10;✓ Dataset created with 2 images&#10;✓ Item 0: pixel_values shape=torch.Size([3, 256, 256]), prompt='A test character number 1'&#10;✓ Item 1: pixel_values shape=torch.Size([3, 256, 256]), prompt='A test character number 2'&#10;&#10;=== Testing Prompt Encoding ===&#10;Test 1: Normal encode_prompt&#10;✓ encode_prompt returned tuple with shapes: torch.Size([1, 77, 768]), torch.Size([1, 1280])&#10;&#10;Test 2: encode_prompt returns None&#10;✗ encode_prompt returned None - THIS WOULD CAUSE THE ERROR!&#10;&#10;... (more tests)&#10;&#10;======================================================================&#10;Test suite completed!&#10;======================================================================&#10;```&#10;&#10;### From `test_integration.py`:&#10;```&#10;======================================================================&#10;INTEGRATION TEST: NoneType Shape Error Replication &amp; Fix&#10;======================================================================&#10;&#10;======================================================================&#10;SIMULATING BROKEN TRAINING LOOP&#10;======================================================================&#10;&#10;[1] Processing batch...&#10;✓ Batch size: 1&#10;&#10;[2] Encoding prompts (BROKEN: returns None)...&#10;✗ ERROR (TypeError): 'NoneType' object is not subscriptable&#10;&#10;... (shows all 3 broken scenarios)&#10;&#10;======================================================================&#10;SIMULATING FIXED TRAINING LOOP WITH VALIDATION&#10;======================================================================&#10;&#10;[1] Processing batch with validation...&#10;✓ Batch validated: size=1, prompts=valid&#10;&#10;[2] Encoding prompts with validation...&#10;✓ Prompt embeddings valid: encoder_hidden_states shape=torch.Size([1, 77, 768])&#10;&#10;... (shows fixed version working)&#10;&#10;✓ FIXED TRAINING LOOP COMPLETED SUCCESSFULLY&#10;&#10;======================================================================&#10;PROPOSED FIX FOR LoRATrainer.py&#10;======================================================================&#10;&#10;def train(self, epochs: int = 10, log_interval: int = 1):&#10;    &quot;&quot;&quot;Fixed version with proper validation and error handling&quot;&quot;&quot;&#10;    # (Full fixed code shown here)&#10;```&#10;&#10;---&#10;&#10;## Key Findings&#10;&#10;### What Causes the Error:&#10;&#10;1. **NoneType objects returned from:**&#10;   - `pipe.encode_prompt()` returns None instead of embeddings&#10;   - `pipe.vae.encode()` returns None&#10;   - `unet()` forward pass returns None&#10;&#10;2. **Accessing attributes on None:**&#10;   - `None[0]` → TypeError: 'NoneType' object is not subscriptable&#10;   - `None.latent_dist` → AttributeError: 'NoneType' object has no attribute 'latent_dist'&#10;   - `None.sample` → AttributeError: 'NoneType' object has no attribute 'sample'&#10;   - `None.shape` → AttributeError: 'NoneType' object has no attribute 'shape'&#10;&#10;3. **Data integrity issues:**&#10;   - Batch prompts are None&#10;   - Batch pixel_values are None&#10;   - Empty prompts causing encoder failures&#10;&#10;### The Fix Strategy:&#10;&#10;Instead of crashing when None is encountered, add validation checks and **skip problematic batches**:&#10;&#10;```python&#10;if variable is None:&#10;    logger.error(&quot;Variable is None at epoch %d batch %d&quot;, epoch + 1, i)&#10;    continue  # Skip to next batch instead of crashing&#10;```&#10;&#10;This allows training to continue while logging which batches had issues.&#10;&#10;---&#10;&#10;## Integration with LoRATrainer&#10;&#10;To apply the fixes, the `train()` method in `LoRATrainer.py` needs these 5 validation checks inserted in the training loop.&#10;&#10;See `test_integration.py` for the complete proposed fix code.&#10;&#10;---&#10;&#10;## Requirements&#10;&#10;- PyTorch&#10;- diffusers&#10;- peft&#10;- PIL&#10;- numpy&#10;- torch.utils.data.DataLoader&#10;&#10;All should be available in your existing environment.&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>